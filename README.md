# РАЗРАБОТКА НЕЙРОИГРЫ С АДАПТИВНЫМ УПРАВЛЕНИЕМ ДЛЯ ТРЕНИНГА КОГНИТИВНЫХ СПОСОБНОСТЕЙ С ИСПОЛЬЗОВАНИЕМ ОБУЧЕНИЯ С ПОДКРЕПЛЕНИЕМ 

Целью работы является разработка нейроигры с адаптивным управлением для тренинга когнитивных способностей с использованием обучения с подкреплением. 

Задачи:

- определить целевую когнитивную функцию и сформулировать критерии оценки;
- разработать базовый прототип игры, ориентированной на тренировку выбранной когнитивной функции;
- формализовать задачу обучения с подкреплением: подобрать среду, пространства действий, награды и наблюдения;
- реализовать игровую среду со сбором данных о действиях пользователя и результатах прохождения заданий;
- обучить RL-агента на основе данных игровых логов и внедрить обученного агента в игровую среду;
- провести тестирование игры, собрать данные о прохождении;
- выполнить сравнительный анализ поведения симулятора и респондентов, оценить качество адаптации и влияние RL-модуля;

Результаты работы включают прототип игры для тренировки выбранной когнитивной функции с механизмом адаптивного управления уровнем сложности, 
а также обоснование выбранного алгоритма для построения модуля адаптивного управления. В рамках исследования проведен эксперимент, 
направленный на анализ изменения показателей прохождения при использовании адаптивной сложности. 

## Концепция игры (Deep Space Ops)

Игрок - оператор космической станции. На станции постоянно возникают сигналы и сбои, которые требуют быстрых решений.
Задача игрока - удерживать стабильность станции, одновременно обрабатывая несколько потоков задач.

## Целевые когнитивные функции

- устойчивое внимание 
- когнитивная гибкость и переключение задач
- рабочая память
- скорость обработки и точность

## Архитектура проекта 

Проект разделен на 4 рабочих контура: `game` (клиент), `backend` (сбор и хранение событий), `training` (обучение RL-модели), `analytics` (оценка эффекта адаптации).

### 1) Игровой клиент (`game/`)

- `game/app.py` — основной цикл игры, запуск задач, применение адаптации, отправка телеметрии.
- `game/tasks/` — когнитивные мини-задачи (radar, sequence, parity, rule-switch и др.).
- `game/adaptation/`
  - `baseline.py` — базовая эвристическая адаптация сложности;
  - `rl_agent.py` — применение обученной модели;
  - `levels.py` — уровни и ограничения параметров сложности.
- `game/runtime/` — инфраструктура клиента:
  - локальные профили и идентификация;
  - очередь неотправленных сессий;
  - HTTP-клиент телеметрии и настройки URL/API key.
- `game/assets/models/ppo_agent.pt` — актуальные веса RL-агента, которые подхватываются игрой в рантайме.

### 2) Backend (`backend/`)

- FastAPI-сервис для приема событий и сервис лидерборда.
- Основные модули:
  - `backend/app/api.py` — REST-эндпоинты (`/health`, `/v1/events`, `/v1/export/raw`, лидерборд);
  - `backend/app/db.py` — работа с SQLite;
  - `backend/app/leaderboard.py` — агрегации для таблицы результатов.
- Хранилище по умолчанию: `backend/data/events.db`.

### 3) Обучение модели (`training/`)

- `training/pipeline.py` — end-to-end пайплайн:
  - выгрузка сырых событий с backend (`/v1/export/raw`);
  - преобразование в JSONL-датасеты;
  - запуск обучения.
- `training/train.py` — обучение policy/value модели на адаптационных переходах.
- `training/data/` — локальные датасеты для обучения:
  - `events.jsonl`, `adaptations.jsonl`, `sessions.jsonl`.
- Результат обучения сохраняется в игровую папку:
  - `game/assets/models/ppo_agent.pt`
  - `game/assets/models/ppo_agent.meta.json`

### 4) Аналитика (`analytics/`)

- `analytics/pipeline.py` — расчет метрик сессионного качества и сравнение `baseline` vs `ppo`.
- `analytics/metrics.py` — метрики по сессиям и агрегаты по режимам.
- `analytics/eval_adaptation.py` — статистическое сравнение режимов адаптации.
- `analytics/raw_transform.py` — подготовка данных из backend-формата.
- Выходные отчеты: `analytics/reports/*.json`.

### Поток данных

1. Игрок проходит сессии в `game`.
2. Клиент отправляет события в `backend` (или кладет во временную очередь при offline).
3. `training/pipeline.py` забирает данные с сервера и переобучает модель.
4. Новые веса попадают в `game/assets/models`, после чего используются в следующих сессиях.
5. `analytics/pipeline.py` строит отчеты по изменению поведения и качеству адаптации.